{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSWLL1aXc1PE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi2AIsHkc_Iu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PjGsY-n1uie"
      },
      "source": [
        "# Data import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWBMY1sodK4L"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Thesis DSS/Second_submission/model_outputs.csv', sep = \";\", index_col = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le8Ao3UNSyeh"
      },
      "outputs": [],
      "source": [
        "# Apply softmax function to each row\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))  # subtracting the max value for numerical stability\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "probabilities = softmax(data.iloc[:, 0:2].values.T)  # Transpose the DataFrame values before applying softmax\n",
        "\n",
        "# The second row will contain the probabilities for class 1\n",
        "class_1_probabilities = probabilities[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKBllWgudVUq"
      },
      "outputs": [],
      "source": [
        "#getting bert features\n",
        "control_features = pd.read_csv('/content/drive/MyDrive/Thesis DSS/Second_submission/selection_variables.csv', sep = \";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzRam2JficK5"
      },
      "outputs": [],
      "source": [
        "control_features['bert_probability'] = class_1_probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5NLYUYTQpFc"
      },
      "outputs": [],
      "source": [
        "control_features.drop(columns = ['review'], inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojTSKEwufJR8"
      },
      "source": [
        "# Consumer pictures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiNO1AtpfLoS"
      },
      "outputs": [],
      "source": [
        "cp_features = pd.read_csv('/content/drive/MyDrive/Thesis DSS/consumer_photo_features.csv', sep = \";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4KTtkHhfiE-"
      },
      "outputs": [],
      "source": [
        "cp_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrIUwDr9fmpT"
      },
      "outputs": [],
      "source": [
        "amazon = pd.read_csv('/content/drive/MyDrive/Thesis DSS/Second_submission/amazon_search_hedonic_clean_merged.csv', sep = \";\")\n",
        "amazon['id'] = amazon.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yU7itCvf5_a"
      },
      "outputs": [],
      "source": [
        "amazon = amazon[['id', 'picture']]\n",
        "\n",
        "#get list of picture and then explode\n",
        "import ast\n",
        "def return_list(string):\n",
        "  if string == 'no':\n",
        "    return ['no']\n",
        "  else:\n",
        "    return ast.literal_eval(string)\n",
        "amazon['picture_list'] = amazon['picture'].apply(return_list)\n",
        "amazon_explode = amazon.explode('picture_list')\n",
        "amazon_explode.reset_index(drop = True, inplace = True)\n",
        "\n",
        "#get the names of the images, instead of link\n",
        "def get_id(link):\n",
        "  if link =='no':\n",
        "    return 'no'\n",
        "  else:\n",
        "    return link.split('/')[-1].split('.')[0]\n",
        "amazon_explode['Name'] = amazon_explode['picture_list'].apply(get_id)\n",
        "\n",
        "#merge and groupby to calculate the mean\n",
        "amazon_merged = pd.merge(amazon_explode, cp_features, on='Name', how='left')\n",
        "amazon_merged.drop(['picture', 'picture_list', 'Name'], inplace = True, axis = 1)\n",
        "amazon_merged = amazon_merged.groupby('id').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G1LMKDN3cIl"
      },
      "outputs": [],
      "source": [
        "#fill all na values with 0 in amazon_merged\n",
        "amazon_merged.fillna(0, inplace = True)\n",
        "\n",
        "amazon_merged.rename(columns=lambda x: x.replace('Column_', 'cp_'), inplace = True)\n",
        "amazon_merged['id'] = amazon_merged.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg-4dMGQuyWG"
      },
      "outputs": [],
      "source": [
        "control_features = pd.concat([control_features, amazon_merged], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akG7iX_oFM97"
      },
      "outputs": [],
      "source": [
        "control_features.drop(['id'], inplace = True, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiILZTLtvaZ7"
      },
      "outputs": [],
      "source": [
        "del amazon_merged\n",
        "del cp_features\n",
        "del amazon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFZMTN-bHJ42"
      },
      "source": [
        "#Profile picture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWUNHFybHNLX"
      },
      "outputs": [],
      "source": [
        "pf_features = pd.read_csv('/content/drive/MyDrive/Thesis DSS/profile_picture_features.csv', sep = \";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKLmHuUeHX7Q"
      },
      "outputs": [],
      "source": [
        "pf_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u9bOnMkHaK7"
      },
      "outputs": [],
      "source": [
        "amazon = pd.read_csv('/content/drive/MyDrive/Thesis DSS/sample_data/sample_dataset.csv', sep = \";\")\n",
        "amazon['id'] = amazon.index\n",
        "\n",
        "def get_name(link):\n",
        "  try:\n",
        "    return link.split('/')[-1].split('.')[0]\n",
        "  except:\n",
        "    return 'other'\n",
        "\n",
        "amazon['Name'] = amazon['profile'].apply(get_name)\n",
        "amazon = amazon[['id', 'Name']]\n",
        "amazon = pd.merge(amazon, pf_features, on = 'Name', how = 'left')\n",
        "amazon.drop(['id', 'Name'], inplace = True, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nWa9y4Kxovg"
      },
      "outputs": [],
      "source": [
        "amazon.rename(columns=lambda x: x.replace('Column_', 'pf_'), inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSEPI4B-x37g"
      },
      "outputs": [],
      "source": [
        "amazon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMcxPWCux7fG"
      },
      "outputs": [],
      "source": [
        "control_features = pd.concat([control_features, amazon], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDOf9qJRoRvF"
      },
      "outputs": [],
      "source": [
        "control_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz6qJG1HmnxA"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CReqhp5xBGWq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(control_features.drop(columns=['helpful']), control_features['helpful'], test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUf_ruWoawQg"
      },
      "outputs": [],
      "source": [
        "#only drop if only looking at text\n",
        "X_train.drop(['n_pictures'], axis = 1, inplace = True)\n",
        "X_val.drop(['n_pictures'], axis = 1, inplace = True)\n",
        "X_test.drop(['n_pictures'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBVETGWk0wQv"
      },
      "outputs": [],
      "source": [
        "dy_train = (y_train != 0).astype(int)\n",
        "dy_val = (y_val != 0).astype(int)\n",
        "dy_test = (y_test != 0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqoKgVrQWy5h"
      },
      "outputs": [],
      "source": [
        "print(accuracy_score((X_train['bert_probability'] > 0.5).astype(int),dy_train))\n",
        "print(accuracy_score((X_val['bert_probability'] > 0.5).astype(int),dy_val))\n",
        "print(accuracy_score((X_test['bert_probability'] > 0.5).astype(int),dy_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB-6SHAlWhgG"
      },
      "outputs": [],
      "source": [
        "#only when looking at img only\n",
        "X_train = X_train[X_train['n_pictures'] != 0]\n",
        "X_val = X_val[X_val['n_pictures'] != 0]\n",
        "X_test = X_test[X_test['n_pictures'] != 0]\n",
        "dy_train = dy_train[X_train.index]\n",
        "dy_val = dy_val[X_val.index]\n",
        "dy_test = dy_test[X_test.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfLrhyOcdOFr"
      },
      "outputs": [],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MM6zPvkpTAe"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#normalize the variables\n",
        "col_normalized = [\n",
        "    'days_diff', 'rating', 'price_sd', 'price_diff',\n",
        "       'rating_diff', 'rating_deviation_sd', 'reviews_sd', 'reviews_diff',\n",
        "                  'review_len', 'price_new_mean', 'rating_mean',\n",
        "       'price_new_min', 'rating_min', 'price_new_max', 'rating_max',\n",
        "       'price_new_median', 'rating_median',\n",
        "       'Height', \"Width\", 'n_pictures'\n",
        "       ]\n",
        "\n",
        "#normalize selected columns\n",
        "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train[col_normalized]), columns = col_normalized)\n",
        "X_val_normalized = pd.DataFrame(scaler.transform(X_val[col_normalized]), columns = col_normalized)\n",
        "X_test_normalized = pd.DataFrame(scaler.transform(X_test[col_normalized]), columns = col_normalized)\n",
        "\n",
        "#drop old columns\n",
        "X_train = X_train.drop(col_normalized, axis=1)\n",
        "X_val = X_val.drop(col_normalized, axis=1)\n",
        "X_test = X_test.drop(col_normalized, axis=1)\n",
        "\n",
        "#concat new normalized columns\n",
        "X_train_normalized.index = X_train.index\n",
        "X_val_normalized.index = X_val.index\n",
        "X_test_normalized.index = X_test.index\n",
        "\n",
        "X_train = pd.concat([X_train, X_train_normalized], axis = 1)\n",
        "X_val = pd.concat([X_val, X_val_normalized], axis = 1)\n",
        "X_test = pd.concat([X_test, X_test_normalized], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZZwy_fuztff"
      },
      "outputs": [],
      "source": [
        "#reorder if pictures are included so all control variables are at the end\n",
        "dummy_col = ['hedonic', 'experience', 'has_video'] + ['Digital Photo Frames', 'Dvd Player', 'Electric Toothbrush', 'Lipstick', 'Mascara', 'Microwave Oven', 'Party Dress', 'Printer', 'Razor', 'Smartphone', 'Vacuum Cleaner'] + ['bert_probability']\n",
        "dummies = X_train[dummy_col]\n",
        "X_train.drop(dummy_col, inplace = True, axis = 1)\n",
        "X_train = pd.concat([X_train, dummies], axis = 1)\n",
        "\n",
        "dummies_val = X_val[dummy_col]\n",
        "X_val.drop(dummy_col, inplace = True, axis = 1)\n",
        "X_val = pd.concat([X_val, dummies_val], axis = 1)\n",
        "\n",
        "dummies_test = X_test[dummy_col]\n",
        "X_test.drop(dummy_col, inplace = True, axis = 1)\n",
        "X_test = pd.concat([X_test, dummies_test], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoheZDoTIdQT"
      },
      "outputs": [],
      "source": [
        "X_train.iloc[:, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD5fhP-vXEI4"
      },
      "outputs": [],
      "source": [
        "dy_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD4KXpVzkg3o"
      },
      "outputs": [],
      "source": [
        "dy_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z94nsiVRRB1K"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg_Yx8njrNQF"
      },
      "outputs": [],
      "source": [
        "X_train.iloc[:, 0:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aztB_d8iTQSr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA()\n",
        "pca.fit(X_train.iloc[:, 0:1000])\n",
        "\n",
        "# Plot the explained variance ratio\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='-')\n",
        "plt.title('Explained Variance Ratio')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance Ratio')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nCUeySHPQsh"
      },
      "outputs": [],
      "source": [
        "#PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Assuming you already have your datasets X_train and X_val\n",
        "\n",
        "# Create a PCA object\n",
        "pca = PCA(n_components=6)  # Specify the number of components (dimensions) you want to reduce to\n",
        "\n",
        "# Fit PCA to your training data\n",
        "pca.fit(X_train.iloc[:, 0:1000])\n",
        "\n",
        "# Transform both the training and validation data to the reduced dimensionality space\n",
        "X_train_pca = pd.DataFrame(pca.transform(X_train.iloc[:, 0:1000]))\n",
        "X_val_pca = pd.DataFrame(pca.transform(X_val.iloc[:, 0:1000]))\n",
        "X_test_pca = pd.DataFrame(pca.transform(X_test.iloc[:, 0:1000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1oyAPp-Qv5H"
      },
      "outputs": [],
      "source": [
        "X_train_pca.index = X_train.index\n",
        "X_val_pca.index = X_val.index\n",
        "X_test_pca.index = X_test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFQsuSKLPmyN"
      },
      "outputs": [],
      "source": [
        "X_train_pca = pd.concat([X_train_pca, X_train.iloc[:, 1000:]], axis = 1)\n",
        "X_val_pca = pd.concat([X_val_pca, X_val.iloc[:, 1000:]], axis = 1)\n",
        "X_test_pca = pd.concat([X_test_pca, X_test.iloc[:, 1000:]], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coF-e1E7vhPn"
      },
      "outputs": [],
      "source": [
        "print(X_train_pca.shape)\n",
        "print(X_val_pca.shape)\n",
        "print(X_test_pca.shape)\n",
        "print(len(dy_train))\n",
        "print(len(dy_val))\n",
        "print(len(dy_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pboEwlyIjMWi"
      },
      "source": [
        "## Image only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb3NJ1X4X1i6"
      },
      "outputs": [],
      "source": [
        "dy_train = dy_train[X_train_pca.index]\n",
        "dy_val = dy_val[X_val_pca.index]\n",
        "dy_test = dy_test[X_test_pca.index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvVWF64nRD5I"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jDWcWGWe956"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgLVVjiYByJ-"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWkKNexFCgpM"
      },
      "outputs": [],
      "source": [
        "#complex model\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import AdamW\n",
        "from keras.layers import BatchNormalization, Dropout, LeakyReLU\n",
        "# Define the optimizer\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "\n",
        "X_train_input = X_train_pca\n",
        "X_val_input = X_val_pca\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=X_train_input.shape[1], activation = 'relu'))\n",
        "#model.add(Dense(32, input_dim=X_train_input.shape[1]))\n",
        "#model.add(Dense(16, input_dim=X_train_input.shape[1]))\n",
        "#model.add(Dense(1, activation='sigmoid', input_dim=X_train.iloc[:, :].shape[1]))  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_input, dy_train, epochs=10, batch_size=64, validation_data=(X_val_input, dy_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akp-jUFhEilg"
      },
      "outputs": [],
      "source": [
        "df_history = pd.DataFrame(history.history)\n",
        "df_history.to_csv('/content/drive/MyDrive/Thesis DSS/Second_submission/Best models/img_pca6/16_img_pca6.csv', sep = \";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OJ9XcEJccyJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "category_performances = pd.DataFrame({'class' : [], 'accuracy_train' : [], 'accuracy_val' : [],\n",
        "                            'precision' : [], 'recall' : [], 'fscore' : [], 'support' : []})\n",
        "\n",
        "predictions = model.predict(X_val)\n",
        "test_pred = (predictions > 0.5).astype(int)\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(dy_val, test_pred)\n",
        "train_acc = df_history['accuracy'].iloc[-1]\n",
        "val_acc = df_history['val_accuracy'].iloc[-1]\n",
        "\n",
        "#category_performances = pd.concat([category_performances, pd.DataFrame({'hedonic' : h, 'experience' : e, 'accuracy' : test_accuracy, 'loss' : test_loss}, index = [0])], axis = 0)\n",
        "category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [0], 'accuracy_train' : [train_acc], 'accuracy_val' : [val_acc],\n",
        "                                              'precision' : [precision[0]], 'recall' : [recall[0]], 'fscore' : [fscore[0]], 'support' : [support[0]]}, index = [0])])\n",
        "category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [1], 'accuracy_train' : [train_acc], 'accuracy_val' : [val_acc],\n",
        "                                              'precision' : [precision[1]], 'recall' : [recall[1]], 'fscore' : [fscore[1]], 'support' : [support[1]]}, index = [0])])\n",
        "category_performances = pd.concat([category_performances, pd.DataFrame({'class' : ['mean'], 'accuracy_train' : [train_acc], 'accuracy_val' : [val_acc],\n",
        "                                              'precision' : [np.average(precision, weights = support)], 'recall' : [np.average(recall, weights = support)], 'fscore' : [np.average(fscore, weights = support)], 'support' : [np.average(support, weights = support)]}, index = [0])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv4_zyU2h4qg"
      },
      "outputs": [],
      "source": [
        "category_performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_8AjzA5fASt"
      },
      "outputs": [],
      "source": [
        "category_performances.to_csv('/content/drive/MyDrive/Thesis DSS/balanced_data/Best models/2layer(128_32_16)_pca20_imgonly_category_performances.csv', sep = \";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CuIPuUy2F9v"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/Thesis DSS/balanced_data/Best models/2layer(128_32_16)_pca20_imgonly.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5PMOLDqEZvz"
      },
      "outputs": [],
      "source": [
        "#PCA training\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "col = 0\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=X_train_pca.shape[1], activation='relu'))  # Input layer with 64 neurons and ReLU activation\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))  # Hidden layer with 32 neurons and ReLU activation\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer with 1 neuron and sigmoid activation for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_pca.iloc[:, col:], dy_train, epochs=20, batch_size=32, validation_data=(X_val_pca.iloc[:, col:], dy_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuwnPo7hdJmb"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wla_TKMoUYaY"
      },
      "outputs": [],
      "source": [
        "!pip install \\\n",
        "    --extra-index-url=https://pypi.nvidia.com \\\n",
        "    cuml-cu12==24.4.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwiXuRJtxSix"
      },
      "outputs": [],
      "source": [
        "from cuml.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGcsokyDT1AS"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBlNVHxReMd1"
      },
      "outputs": [],
      "source": [
        "#grid search decision tree\n",
        "X_train_input = X_train_pca\n",
        "X_val_input = X_val_pca\n",
        "grid_search = pd.DataFrame({'class' : [], 'n' : [], 'max_depth' : [], 'features' : [], 'accuracy_train' : [], 'accuracy_val' : [],\n",
        "                            'precision' : [], 'recall' : [], 'fscore' : [], 'support' : []})\n",
        "cols = [\n",
        "    #range(720)) + #first layer\n",
        "   #list(range(3072, 4072)) + #cp\n",
        "    #list(range(4072, 5072)), #pf\n",
        "    list(range(0, X_train_input.shape[1])) #control\n",
        "][0]\n",
        "\n",
        "\n",
        "#col = 3072\n",
        "#end_col = X_train.shape[1]\n",
        "for n_estimators in [1]:\n",
        "  for max_depth in [3, 5, 10, 20]:\n",
        "    for max_features in ['log2', 'sqrt', 0.3, 0.5]:\n",
        "      rf_classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth = max_depth, max_features = max_features, random_state=42, bootstrap = False)\n",
        "      rf_classifier.fit(X_train_input.iloc[:, cols], dy_train)\n",
        "\n",
        "      train_pred = rf_classifier.predict(X_train_input.iloc[:, cols])\n",
        "      print(n_estimators, max_depth, max_features)\n",
        "      accuracy_train = accuracy_score(dy_train, train_pred)\n",
        "      print(accuracy_train)\n",
        "\n",
        "      val_pred = rf_classifier.predict(X_val_input.iloc[:, cols]) #this returns 0.75\n",
        "      #rf_classifier.fit(X_train, dy_train)\n",
        "      #val_pred = rf_classifier.predict(X_val)\n",
        "      accuracy = accuracy_score(dy_val, val_pred)\n",
        "      precision, recall, fscore, support = precision_recall_fscore_support(dy_val, val_pred)\n",
        "      grid_search = pd.concat([grid_search, pd.DataFrame({'class' : [0], 'n' : [n_estimators], 'max_depth' : [max_depth], 'features' : [max_features], 'accuracy_train' : [accuracy_train], 'accuracy_val' : [accuracy],\n",
        "                                                    'precision' : [precision[0]], 'recall' : [recall[0]], 'fscore' : [fscore[0]], 'support' : [support[0]]}, index = [0])])\n",
        "      grid_search = pd.concat([grid_search, pd.DataFrame({'class' : [1], 'n' : [n_estimators], 'max_depth' : [max_depth], 'features' : [max_features], 'accuracy_train' : [accuracy_train], 'accuracy_val' : [accuracy],\n",
        "                                                    'precision' : [precision[1]], 'recall' : [recall[1]], 'fscore' : [fscore[1]], 'support' : [support[1]]}, index = [0])])\n",
        "      grid_search = pd.concat([grid_search, pd.DataFrame({'class' : ['mean'], 'n' : [n_estimators], 'max_depth' : [max_depth], 'features' : [max_features], 'accuracy_train' : [accuracy_train], 'accuracy_val' : [accuracy],\n",
        "                                                     'precision' : [np.average(precision, weights = support)], 'recall' : [np.average(recall, weights = support)], 'fscore' : [np.average(fscore, weights = support)], 'support' : [np.average(support, weights = support)]}, index = [0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lh7j9H1eSo5"
      },
      "outputs": [],
      "source": [
        "grid_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP8Woz6J-EcF"
      },
      "outputs": [],
      "source": [
        "grid_search.to_csv('/content/drive/MyDrive/Thesis DSS/balanced_data/Best models/imgonly_balanced/dt_imgonly.csv', sep = \";\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBf-rMEyfBPF"
      },
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPVHU7B4bRuP"
      },
      "outputs": [],
      "source": [
        "col = 0\n",
        "end_col = X_train_input.shape[1]\n",
        "X_train_input.iloc[:, col:end_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc9irsr8HO0Z"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "X_train_pca.columns = X_train_pca.columns.astype(str)\n",
        "X_val_pca.columns = X_val_pca.columns.astype(str)\n",
        "X_test_pca.columns = X_test_pca.columns.astype(str)\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_pca, dy_train = smote.fit_resample(X_train_pca, dy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkMFea0_IHnS"
      },
      "outputs": [],
      "source": [
        "X_train_pca.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-ZBrFI46YYu"
      },
      "outputs": [],
      "source": [
        "#grid search random forest\n",
        "X_train_input = X_train_pca\n",
        "X_val_input = X_val_pca\n",
        "\n",
        "grid_search = pd.DataFrame({'class' : [], 'n' : [], 'max_depth' : [], 'features' : [], 'min_samples' : [],'accuracy_train' : [], 'accuracy_val' : [],\n",
        "                            'precision' : [], 'recall' : [], 'fscore' : [], 'support' : []})\n",
        "col = 0\n",
        "end_col = X_train_input.shape[1]\n",
        "for n_estimators in [20, 100, 500, 2000]:\n",
        "  #increased depth for cp only\n",
        "  for max_depth in [5, 10, 20]:\n",
        "    for max_features in ['log2', 'sqrt']:\n",
        "      for min_samples in [25, 50, 100]:\n",
        "        rf_classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth = max_depth, max_features = max_features, min_samples_leaf = min_samples, random_state=42)\n",
        "        rf_classifier.fit(X_train_input.iloc[:, col:end_col], dy_train)\n",
        "\n",
        "        train_pred = rf_classifier.predict(X_train_input.iloc[:, col:end_col])\n",
        "        print(n_estimators, max_depth, max_features, min_samples)\n",
        "        accuracy_train = accuracy_score(dy_train, train_pred)\n",
        "\n",
        "        val_pred = rf_classifier.predict(X_val_input.iloc[:, col:end_col]) #this returns 0.75\n",
        "        #rf_classifier.fit(X_train, dy_train)\n",
        "        #val_pred = rf_classifier.predict(X_val)\n",
        "        accuracy = accuracy_score(dy_val, val_pred)\n",
        "        print(\"train: \", round(accuracy_train, 3), \"val: \", round(accuracy, 3))\n",
        "        precision, recall, fscore, support = precision_recall_fscore_support(dy_val, val_pred)\n",
        "        #only take models that don't overfit into consideration\n",
        "        #if accuracy_train - accuracy < 0.05:\n",
        "        grid_search = pd.concat([grid_search, pd.DataFrame({'class' : [0], 'n' : [n_estimators], 'max_depth' : [max_depth], 'features' : [max_features], 'min_samples' : [min_samples], 'accuracy_train' : [accuracy_train], 'accuracy_val' : [accuracy],\n",
        "                                                      'precision' : [precision[0]], 'recall' : [recall[0]], 'fscore' : [fscore[0]], 'support' : [support[0]]}, index = [0])])\n",
        "        grid_search = pd.concat([grid_search, pd.DataFrame({'class' : [1], 'n' : [n_estimators], 'max_depth' : [max_depth], 'features' : [max_features], 'min_samples' : [min_samples], 'accuracy_train' : [accuracy_train], 'accuracy_val' : [accuracy],\n",
        "                                                      'precision' : [precision[1]], 'recall' : [recall[1]], 'fscore' : [fscore[1]], 'support' : [support[1]]}, index = [0])])\n",
        "        grid_search = pd.concat([grid_search, pd.DataFrame({'class' : ['mean'], 'n' : [n_estimators], 'max_depth' : [max_depth], 'features' : [max_features], 'min_samples' : [min_samples], 'accuracy_train' : [accuracy_train], 'accuracy_val' : [accuracy],\n",
        "                                                      'precision' : [np.average(precision, weights = support)], 'recall' : [np.average(recall, weights = support)], 'fscore' : [np.average(fscore, weights = support)], 'support' : [np.average(support, weights = support)]}, index = [0])])\n",
        "grid_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLtiS672hs8o"
      },
      "outputs": [],
      "source": [
        "grid_search['accuracy_val'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cdZ4DyTU06q"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 110)\n",
        "grid_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk09RwLFamZd"
      },
      "outputs": [],
      "source": [
        "grid_search.to_csv('/content/drive/MyDrive/Thesis DSS/Second_submission/Best models/img_pca6/rf_.csv', sep = \";\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilFXqCs_dBq5"
      },
      "source": [
        "##GBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtmkSxcddDJV"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Example of XGBoost with GPU\n",
        "param = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'tree_method': 'gpu_hist',  # Enable GPU acceleration\n",
        "    'predictor': 'gpu_predictor'  # Use GPU for predictions\n",
        "}\n",
        "dtrain = xgb.DMatrix(data=X_train, label=dy_train)\n",
        "bst = xgb.train(param, dtrain, num_boost_round=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNoGcauKnNH7"
      },
      "outputs": [],
      "source": [
        "preds = bst.predict(dtrain)\n",
        "accuracy = accuracy_score(dy_train, (preds > 0.5).astype(int))\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCoFRxcHdO36"
      },
      "outputs": [],
      "source": [
        "#test bst on vali: 0.7629133081098864\n",
        "dval = xgb.DMatrix(data=X_val, label=dy_val)\n",
        "preds = bst.predict(dval)\n",
        "accuracy = accuracy_score(dy_val, (preds > 0.5).astype(int))\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58vJZJg6eOPU"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Define parameters\n",
        "param = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'tree_method': 'gpu_hist',  # Enable GPU acceleration\n",
        "    'max_depth': 7,  # Maximum tree depth\n",
        "    'learning_rate': 0.1,  # Learning rate\n",
        "    'gamma': 0,  # Minimum loss reduction\n",
        "    'subsample': 1,  # Subsample ratio of training instances\n",
        "    'colsample_bytree': 0.5,  # Subsample ratio of columns\n",
        "    'lambda': 0,  # L2 regularization term\n",
        "}\n",
        "\n",
        "# Training data\n",
        "dtrain = xgb.DMatrix(data=X_train, label=dy_train)\n",
        "\n",
        "# Train the model\n",
        "bst = xgb.train(param, dtrain, num_boost_round=100, evals=[(dtrain, 'train')], verbose_eval=False)\n",
        "dval = xgb.DMatrix(data=X_val, label=dy_val)\n",
        "preds = bst.predict(dtrain)\n",
        "accuracy = accuracy_score(dy_train, (preds > 0.5).astype(int))\n",
        "print(\"train: \", accuracy)\n",
        "preds = bst.predict(dval)\n",
        "accuracy = accuracy_score(dy_val, (preds > 0.5).astype(int))\n",
        "print(\"val: \",accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb994d46iwRu"
      },
      "outputs": [],
      "source": [
        "#grid search XGB\n",
        "X_train_input = X_train_pca\n",
        "X_val_input = X_val_pca\n",
        "\n",
        "grid_search = pd.DataFrame({'class' : [], 'num_boost_round' : [], 'max_depth' : [], 'colsample_bytree' : [], 'lambda_term' : [],'accuracy_train' : [], 'accuracy_val' : [],\n",
        "                            'precision' : [], 'recall' : [], 'fscore' : [], 'support' : []})\n",
        "\n",
        "for num_boost_round in [20, 100, 200]:\n",
        "  #increased depth for cp only\n",
        "  for max_depth in [3, 5, 10]:\n",
        "    for colsample_bytree in [0.2, 0.8, 1]:\n",
        "      for lambda_term in [0, 0.01, 0.1, 0.5]:\n",
        "        param = {\n",
        "            'objective': 'binary:logistic',\n",
        "            'tree_method': 'gpu_hist',  # Enable GPU acceleration\n",
        "            'max_depth': max_depth,  # Maximum tree depth\n",
        "            'subsample': 1,  # Subsample ratio of training instances\n",
        "            'colsample_bytree': colsample_bytree,  # Subsample ratio of columns\n",
        "            'lambda': lambda_term,  # L2 regularization term\n",
        "        }\n",
        "\n",
        "        # Training data\n",
        "        dtrain = xgb.DMatrix(data=X_train_input, label=dy_train)\n",
        "\n",
        "        # Train the model\n",
        "        bst = xgb.train(param, dtrain, num_boost_round=num_boost_round, evals=[(dtrain, 'train')], verbose_eval=False)\n",
        "\n",
        "        train_pred = bst.predict(dtrain)\n",
        "        train_pred = (train_pred > 0.5).astype(int)\n",
        "        accuracy_train = accuracy_score(dy_train, train_pred)\n",
        "\n",
        "        dval = xgb.DMatrix(data=X_val_input, label=dy_val)\n",
        "        val_pred = bst.predict(dval)\n",
        "        val_pred = (val_pred > 0.5).astype(int)\n",
        "        accuracy = accuracy_score(dy_val, val_pred)\n",
        "        print(num_boost_round, max_depth, colsample_bytree, lambda_term)\n",
        "        print(\"train: \", round(accuracy_train, 3), \"val: \", round(accuracy, 3))\n",
        "        precision, recall, fscore, support = precision_recall_fscore_support(dy_val, val_pred)\n",
        "        #only take models that don't overfit into consideration\n",
        "        #if accuracy_train - accuracy < 0.05:\n",
        "        grid_search = pd.concat([grid_search, pd.DataFrame({'class' : [0], 'num_boost_round' : [num_boost_round], 'max_depth' : [max_depth], 'colsample_bytree' : [colsample_bytree], 'lambda_term' : [lambda_term], 'accuracy_train' : [accuracy_train], 'accuracy_val' : [accuracy],\n",
        "                                                      'precision' : [precision[0]], 'recall' : [recall[0]], 'fscore' : [fscore[0]], 'support' : [support[0]]}, index = [0])])\n",
        "        grid_search = pd.concat([grid_search, pd.DataFrame({'class' : [1], 'num_boost_round' : [num_boost_round], 'max_depth' : [max_depth], 'colsample_bytree' : [colsample_bytree], 'lambda_term' : [lambda_term], 'accuracy_train' : [accuracy_train], 'accuracy_val' : [accuracy],\n",
        "                                                      'precision' : [precision[1]], 'recall' : [recall[1]], 'fscore' : [fscore[1]], 'support' : [support[1]]}, index = [0])])\n",
        "        grid_search = pd.concat([grid_search, pd.DataFrame({'class' : ['mean'], 'num_boost_round' : [num_boost_round], 'max_depth' : [max_depth], 'colsample_bytree' : [colsample_bytree], 'lambda_term' : [lambda_term], 'accuracy_train' : [accuracy_train], 'accuracy_val' : [accuracy],\n",
        "                                                      'precision' : [np.average(precision, weights = support)], 'recall' : [np.average(recall, weights = support)], 'fscore' : [np.average(fscore, weights = support)], 'support' : [np.average(support, weights = support)]}, index = [0])])\n",
        "grid_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4TOTcYjk1XT"
      },
      "outputs": [],
      "source": [
        "grid_search.to_csv('/content/drive/MyDrive/Thesis DSS/Second_submission/Best models/img_pca6/xgb_pca.csv', sep = \";\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKNUnI5zmQZ0"
      },
      "outputs": [],
      "source": [
        "#max acc\n",
        "grid_search['accuracy_val'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GpKM6ZaHgAO"
      },
      "source": [
        "# Compare all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InlvtTQiHhoS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory containing the CSV files\n",
        "directory = '/content/drive/MyDrive/Thesis DSS/Second_submission/Best models/imgonly'\n",
        "\n",
        "# Initialize variables to store maximum accuracy and corresponding file name\n",
        "max_accuracy = 0\n",
        "max_accuracy_file = ''\n",
        "\n",
        "# Loop through each file in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.csv'):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "\n",
        "        # Read the CSV file into a pandas DataFrame\n",
        "        df = pd.read_csv(filepath, sep = \";\")\n",
        "\n",
        "        # Find the maximum accuracy in the 'val_accuracy' column\n",
        "        try:\n",
        "          try:\n",
        "            #get last epoch of the nn\n",
        "            max_val_accuracy = df['val_accuracy'].iloc[-1]\n",
        "            print(filename, max_val_accuracy)\n",
        "          except:\n",
        "            #filter df where accuracy_train-accuracy_val does not exceed 0.05\n",
        "            df = df[df['accuracy_train'] - df['accuracy_val'] < 0.05]\n",
        "            max_val_accuracy = df['accuracy_val'].max()\n",
        "            print(filename, max_val_accuracy)\n",
        "        except:\n",
        "          print('failed ', filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od6O1IQmwCCQ"
      },
      "source": [
        "#Best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1o69NQ2nmeP"
      },
      "source": [
        "## Full data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vzk_oSrffTgd"
      },
      "outputs": [],
      "source": [
        "X_train_input = X_train_pca\n",
        "X_val_input = X_val_pca\n",
        "X_test_input = X_test_pca\n",
        "\n",
        "param = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'tree_method': 'gpu_hist',  # Enable GPU acceleration\n",
        "    'max_depth': 5,  # Maximum tree depth\n",
        "    'subsample': 1,  # Subsample ratio of training instances\n",
        "    'colsample_bytree': 0.8,  # Subsample ratio of columns\n",
        "    'lambda': 0.01,  # L2 regularization term\n",
        "}\n",
        "\n",
        "# Training data\n",
        "dtrain = xgb.DMatrix(data=X_train_input, label=dy_train)\n",
        "\n",
        "# Train the model\n",
        "bst = xgb.train(param, dtrain, num_boost_round=100, evals=[(dtrain, 'train')], verbose_eval=False)\n",
        "\n",
        "train_pred = bst.predict(dtrain)\n",
        "train_pred = (train_pred > 0.5).astype(int)\n",
        "accuracy_train = accuracy_score(dy_train, train_pred)\n",
        "print(accuracy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTlmNqr2iMPC"
      },
      "outputs": [],
      "source": [
        "X_test_input = pd.concat([X_test_pca, dy_test], axis = 1)\n",
        "X_test_input['helpful']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HeVHQnRwEqi"
      },
      "outputs": [],
      "source": [
        "#import confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "category_performances = pd.DataFrame({'class' : [], 'hedonic' : [], 'experience' : [], 'accuracy' : [], 'loss' : [],\n",
        "                                      'tn' : [], 'fp' : [], 'fn' : [], 'tp' : [],\n",
        "                            'precision' : [], 'recall' : [], 'fscore' : [], 'support' : []})\n",
        "\n",
        "def get_performance_metrics(h, e, X_test_input, category_performances):\n",
        "    dval = xgb.DMatrix(data=X_test_input.iloc[:,:-1], label=X_test_input['helpful'])\n",
        "    test_pred = bst.predict(dval)\n",
        "    test_pred = (test_pred > 0.5).astype(int)\n",
        "    test_accuracy = accuracy_score(X_test_input['helpful'], test_pred)\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(X_test_input['helpful'], test_pred)\n",
        "    print(test_accuracy)\n",
        "    cm = confusion_matrix(X_test_input['helpful'], test_pred)\n",
        "    test_loss = None\n",
        "    #category_performances = pd.concat([category_performances, pd.DataFrame({'hedonic' : h, 'experience' : e, 'accuracy' : test_accuracy, 'loss' : test_loss}, index = [0])], axis = 0)\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [0], 'hedonic' : [h], 'experience' : [e], 'accuracy' : [test_accuracy], 'loss' : [test_loss],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [precision[0]], 'recall' : [recall[0]], 'fscore' : [fscore[0]], 'support' : [support[0]]}, index = [0])])\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [1], 'hedonic' : [h],  'experience' : [e], 'accuracy' : [test_accuracy], 'loss' : [test_loss],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [precision[1]], 'recall' : [recall[1]], 'fscore' : [fscore[1]], 'support' : [support[1]]}, index = [0])])\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : ['mean'], 'hedonic' : [h], 'experience' : [e], 'accuracy' : [test_accuracy], 'loss' : [test_loss],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [np.average(precision, weights = support)], 'recall' : [np.average(recall, weights = support)], 'fscore' : [np.average(fscore, weights = support)], 'support' : [np.average(support, weights = support)]}, index = [0])])\n",
        "    return category_performances\n",
        "\n",
        "for h in [0,1]:\n",
        "  for e in [0,1]:\n",
        "    X_test_input = pd.concat([X_test_pca, dy_test], axis = 1)\n",
        "    X_test_input = X_test_input[(X_test_input['hedonic'] == h) & (X_test_input['experience'] == e)]\n",
        "    category_performances = get_performance_metrics(h, e, X_test_input, category_performances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13goQR69KDAI"
      },
      "outputs": [],
      "source": [
        "#add also the full dataset\n",
        "X_test_input = pd.concat([X_test_pca, dy_test], axis = 1)\n",
        "category_performances = get_performance_metrics('full', 'full', X_test_input, category_performances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2d1qqJT4J7y"
      },
      "outputs": [],
      "source": [
        "category_performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwJqTu0_3miW"
      },
      "outputs": [],
      "source": [
        "category_performances.to_csv('/content/drive/MyDrive/Thesis DSS/Second_submission/history/category_performances.csv', sep = \";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yln7l6txnsJH"
      },
      "source": [
        "## Subset (img only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd7dvnP-pwJr"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "X_train_pca.columns = X_train_pca.columns.astype(str)\n",
        "X_val_pca.columns = X_val_pca.columns.astype(str)\n",
        "X_test_pca.columns = X_test_pca.columns.astype(str)\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_pca_smote, dy_train_smote = smote.fit_resample(X_train_pca, dy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQVOj-1iqLGy"
      },
      "outputs": [],
      "source": [
        "#create empty dataframe with X_test_pca columns\n",
        "X_train_pca_smote = pd.DataFrame(columns = X_train_pca.columns)\n",
        "y_train_smote = []\n",
        "for h in [0,1]:\n",
        "  for e in [0,1]:\n",
        "    X_train_input = pd.concat([X_train_pca, dy_train], axis = 1)\n",
        "    X_train_input = X_train_input[(X_train_input['hedonic'] == h) & (X_train_input['experience'] == e)]\n",
        "    X_train_pca_smote_cat, dy_train_smote_cat = smote.fit_resample(X_train_input.iloc[:, :-1], X_train_input['helpful'])\n",
        "    X_train_pca_smote = pd.concat([X_train_pca_smote, X_train_pca_smote_cat], axis = 0)\n",
        "    y_train_smote = y_train_smote + list(dy_train_smote_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm16tibarJxY"
      },
      "outputs": [],
      "source": [
        "len(y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ9fBX5_rVzI"
      },
      "outputs": [],
      "source": [
        "len(y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDSZ65zIsE2f"
      },
      "outputs": [],
      "source": [
        "#convert X_train_pca_smote to floats\n",
        "X_train_pca_smote = X_train_pca_smote.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SZADC84nu5j"
      },
      "outputs": [],
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators=2000, max_depth = 20, max_features = 'sqrt', min_samples_leaf = 25, random_state=42)\n",
        "rf_classifier.fit(X_train_pca_smote, pd.Series(y_train_smote))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx-tQCOxoJXU"
      },
      "outputs": [],
      "source": [
        "category_performances = pd.DataFrame({'class' : [], 'h' : [], 'e' : [], 'test_acc' : [],\n",
        "                                      'tn' : [], 'fp' : [], 'fn' : [], 'tp' : [],\n",
        "                            'precision' : [], 'recall' : [], 'fscore' : [], 'support' : []})\n",
        "\n",
        "\n",
        "def get_performance_metrics(h, e, X_test_input, category_performances, model):\n",
        "    test_pred = model.predict(X_test_input.iloc[:, :-1])\n",
        "    dy_val = X_test_input.iloc[:, -1]\n",
        "    test_acc = accuracy_score(dy_val, test_pred)\n",
        "    print(test_acc)\n",
        "\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(dy_val, test_pred)\n",
        "    cm = confusion_matrix(dy_val, test_pred)\n",
        "    #category_performances = pd.concat([category_performances, pd.DataFrame({'hedonic' : h, 'experience' : e, 'accuracy' : test_accuracy, 'loss' : test_loss}, index = [0])], axis = 0)\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [0], 'h' : [h], 'e' : [e], 'test_acc' : [test_acc],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [precision[0]], 'recall' : [recall[0]], 'fscore' : [fscore[0]], 'support' : [support[0]]}, index = [0])])\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [1], 'h' : [h],  'e' : [e], 'test_acc' : [test_acc],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [precision[1]], 'recall' : [recall[1]], 'fscore' : [fscore[1]], 'support' : [support[1]]}, index = [0])])\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : ['mean'], 'h' : [h], 'e' : [e], 'test_acc' : [test_acc],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [np.average(precision, weights = support)], 'recall' : [np.average(recall, weights = support)], 'fscore' : [np.average(fscore, weights = support)], 'support' : [np.average(support, weights = support)]}, index = [0])])\n",
        "    return category_performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ27Aw0qoVol"
      },
      "outputs": [],
      "source": [
        "\n",
        "for h in [0,1]:\n",
        "  for e in [0,1]:\n",
        "    X_test_input = pd.concat([X_test_pca, dy_test], axis = 1)\n",
        "    X_test_input = X_test_input[(X_test_input['hedonic'] == h) & (X_test_input['experience'] == e)]\n",
        "    category_performances = get_performance_metrics(h, e, X_test_input, category_performances, rf_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-i6evFapOLU"
      },
      "outputs": [],
      "source": [
        "category_performances = get_performance_metrics(2, 2, pd.concat([X_test_pca, dy_test], axis = 1), category_performances, rf_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_q5430xpYsX"
      },
      "outputs": [],
      "source": [
        "category_performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XU_YYe0XpRlA"
      },
      "outputs": [],
      "source": [
        "category_performances.to_csv('/content/drive/MyDrive/Thesis DSS/Second_submission/history/img_only_performance_per_category_cat_smote.csv', sep = \";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4MmzzJU0-GQ"
      },
      "source": [
        "#Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5yDWyKA09Mg"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5nizvhw3iEE"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9nU-3Xj15aF"
      },
      "outputs": [],
      "source": [
        "X_train['review'] = X_train['review'].fillna('')\n",
        "X_val['review'] = X_val['review'].fillna('')\n",
        "X_test['review'] = X_test['review'].fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TYRseC5rt5f"
      },
      "outputs": [],
      "source": [
        "X_train['review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1emz3wO01p-_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def remove_punctuation(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text)\n",
        "# Apply the function to each element in the 'review' column using str.replace\n",
        "X_train['review_clean'] = X_train['review'].apply(remove_punctuation)\n",
        "print(X_train['review_clean'].iloc[0])\n",
        "#lowercase everything\n",
        "X_train['review_clean'] = X_train['review_clean'].str.lower()\n",
        "print(X_train['review_clean'].iloc[0])\n",
        "#remove stopwords\n",
        "stop = stopwords.words('english')\n",
        "X_train['review_clean'] = X_train['review_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "print(X_train['review_clean'].iloc[0])\n",
        "#stemming\n",
        "\n",
        "porter = PorterStemmer()\n",
        "X_train['review_clean'] = X_train['review_clean'].apply(lambda x: ' '.join([porter.stem(word) for word in x.split()]))\n",
        "print(X_train['review_clean'].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb2vq4p534ee"
      },
      "outputs": [],
      "source": [
        "X_val['review_clean'] = X_val['review'].apply(remove_punctuation)\n",
        "#lowercase everything\n",
        "X_val['review_clean'] = X_val['review_clean'].str.lower()\n",
        "#remove stopwords\n",
        "X_val['review_clean'] = X_val['review_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "#stemming\n",
        "porter = PorterStemmer()\n",
        "X_val['review_clean'] = X_val['review_clean'].apply(lambda x: ' '.join([porter.stem(word) for word in x.split()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f529KEkc4GLu"
      },
      "outputs": [],
      "source": [
        "X = vectorizer.fit_transform(X_train['review_clean'])\n",
        "X_v = vectorizer.transform(X_val['review_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NETPZEit4ntG"
      },
      "outputs": [],
      "source": [
        "# Create a KNN classifier\n",
        "from cuml.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Fit the classifier to your data\n",
        "knn.fit(X, dy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oujWliJC5JX7"
      },
      "outputs": [],
      "source": [
        "from cuml.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD1fBz7R5zqU"
      },
      "outputs": [],
      "source": [
        "category_performances = pd.DataFrame({'class' : [], 'p1' : [], 'p2' : [], 'train_acc' : [], 'test_acc' : [],\n",
        "                                      'tn' : [], 'fp' : [], 'fn' : [], 'tp' : [],\n",
        "                            'precision' : [], 'recall' : [], 'fscore' : [], 'support' : []})\n",
        "\n",
        "\n",
        "def get_performance_metrics(p1, p2, X, X_test_input, dy_train, dy_val, category_performances, model):\n",
        "    y_train_pred = model.predict(X)\n",
        "    train_acc = accuracy_score(dy_train, y_train_pred)\n",
        "\n",
        "    test_pred = model.predict(X_test_input)\n",
        "\n",
        "    test_acc = accuracy_score(dy_val, test_pred)\n",
        "    print(test_acc)\n",
        "\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(dy_val, test_pred)\n",
        "    cm = confusion_matrix(dy_val, test_pred)\n",
        "    #category_performances = pd.concat([category_performances, pd.DataFrame({'hedonic' : h, 'experience' : e, 'accuracy' : test_accuracy, 'loss' : test_loss}, index = [0])], axis = 0)\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [0], 'p1' : [p1], 'p2' : [p2], 'train_acc' : [train_acc], 'test_acc' : [test_acc],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [precision[0]], 'recall' : [recall[0]], 'fscore' : [fscore[0]], 'support' : [support[0]]}, index = [0])])\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [1], 'p1' : [p1],  'p2' : [p2], 'train_acc' : [train_acc], 'test_acc' : [test_acc],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [precision[1]], 'recall' : [recall[1]], 'fscore' : [fscore[1]], 'support' : [support[1]]}, index = [0])])\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : ['mean'], 'p1' : [p1], 'p2' : [p2], 'train_acc' : [train_acc], 'test_acc' : [test_acc],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [np.average(precision, weights = support)], 'recall' : [np.average(recall, weights = support)], 'fscore' : [np.average(fscore, weights = support)], 'support' : [np.average(support, weights = support)]}, index = [0])])\n",
        "    return category_performances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72q1-OP18V4u"
      },
      "outputs": [],
      "source": [
        "for k in [5, 10, 50]:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "  # Fit the classifier to your data\n",
        "  knn.fit(X, dy_train)\n",
        "  category_performances = get_performance_metrics('knn', k, X, X_v, dy_train, dy_val, category_performances, knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWII6lz0-mHP"
      },
      "outputs": [],
      "source": [
        "category_performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62hSAFeL--AH"
      },
      "outputs": [],
      "source": [
        "from cuml.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYcbTmi_AW6a"
      },
      "outputs": [],
      "source": [
        "for k in [0.1, 1, 10]:\n",
        "  # Initialize the Naive Bayes classifier with Laplace smoothing parameter set to 1\n",
        "  nb_classifier = MultinomialNB(alpha=k)\n",
        "\n",
        "  # Fit the classifier to your data\n",
        "  nb_classifier.fit(X, dy_train)\n",
        "  category_performances = get_performance_metrics('nb', k, X, X_v, dy_train, dy_val, category_performances, nb_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qph-VhNA772"
      },
      "outputs": [],
      "source": [
        "from cuml.linear_model import LogisticRegression\n",
        "for c in [0.1, 0.5, 1]:\n",
        "  reg = LogisticRegression(C = c)\n",
        "  # Fit the classifier to your data\n",
        "  reg.fit(X, dy_train)\n",
        "  category_performances = get_performance_metrics('lr', c, X, X_v, dy_train, dy_val, category_performances, reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV072rGjC8DB"
      },
      "outputs": [],
      "source": [
        "category_performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJBn6h3sEhOS"
      },
      "outputs": [],
      "source": [
        "category_performances.to_csv('/content/drive/MyDrive/Thesis DSS/Second_submission/history/base_line_performance.csv', sep = \";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0KS4NQBdpiB"
      },
      "source": [
        "# Test performance random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_NNywIFdsDM"
      },
      "outputs": [],
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators=2000, max_depth = 10, max_features = 'log2', min_samples_leaf = 50, random_state=42)\n",
        "rf_classifier.fit(X_train_pca, dy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFGyo54Ud3NY"
      },
      "outputs": [],
      "source": [
        "category_performances = pd.DataFrame({'class' : [], 'h' : [], 'e' : [], 'test_acc' : [],\n",
        "                                      'tn' : [], 'fp' : [], 'fn' : [], 'tp' : [],\n",
        "                            'precision' : [], 'recall' : [], 'fscore' : [], 'support' : []})\n",
        "\n",
        "\n",
        "def get_performance_metrics(h, e, X_test_input, category_performances, model):\n",
        "    test_pred = model.predict(X_test_input.iloc[:, :-1])\n",
        "    dy_val = X_test_input.iloc[:, -1]\n",
        "    test_acc = accuracy_score(dy_val, test_pred)\n",
        "    print(test_acc)\n",
        "\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(dy_val, test_pred)\n",
        "    cm = confusion_matrix(dy_val, test_pred)\n",
        "    #category_performances = pd.concat([category_performances, pd.DataFrame({'hedonic' : h, 'experience' : e, 'accuracy' : test_accuracy, 'loss' : test_loss}, index = [0])], axis = 0)\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [0], 'h' : [h], 'e' : [e], 'test_acc' : [test_acc],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [precision[0]], 'recall' : [recall[0]], 'fscore' : [fscore[0]], 'support' : [support[0]]}, index = [0])])\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : [1], 'h' : [h],  'e' : [e], 'test_acc' : [test_acc],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [precision[1]], 'recall' : [recall[1]], 'fscore' : [fscore[1]], 'support' : [support[1]]}, index = [0])])\n",
        "    category_performances = pd.concat([category_performances, pd.DataFrame({'class' : ['mean'], 'h' : [h], 'e' : [e], 'test_acc' : [test_acc],\n",
        "                                                                            'tn' : cm[0,0], 'fp' : cm[0,1], 'fn' : cm[1,0], 'tp' : cm[1,1],\n",
        "                                                  'precision' : [np.average(precision, weights = support)], 'recall' : [np.average(recall, weights = support)], 'fscore' : [np.average(fscore, weights = support)], 'support' : [np.average(support, weights = support)]}, index = [0])])\n",
        "    return category_performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnndUu14eF_g"
      },
      "outputs": [],
      "source": [
        "for h in [0,1]:\n",
        "  for e in [0,1]:\n",
        "    X_test_input = pd.concat([X_test_pca, dy_test], axis = 1)\n",
        "    X_test_input = X_test_input[(X_test_input['hedonic'] == h) & (X_test_input['experience'] == e)]\n",
        "    category_performances = get_performance_metrics(h, e, X_test_input, category_performances, rf_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv26DlnLfzLd"
      },
      "outputs": [],
      "source": [
        "category_performances = get_performance_metrics(2, 2, pd.concat([X_test_pca, dy_test], axis = 1), category_performances, rf_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxZ1fg8jhrDL"
      },
      "outputs": [],
      "source": [
        "category_performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXoman8xiJ_N"
      },
      "outputs": [],
      "source": [
        "category_performances.to_csv('/content/drive/MyDrive/Thesis DSS/balanced_data/Best models/imgonly_balanced/img_only_performance_per_category.csv', sep = \";\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ojTSKEwufJR8",
        "fFZMTN-bHJ42",
        "pboEwlyIjMWi",
        "pGcsokyDT1AS",
        "k4MmzzJU0-GQ",
        "N0KS4NQBdpiB"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}