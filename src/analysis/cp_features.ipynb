{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1cf97c",
   "metadata": {},
   "source": [
    "This file extracts features from the consumer photos using EfficientNetV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08776145",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46d6e1-ee30-478c-af44-8e85e00e48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890438e0",
   "metadata": {},
   "source": [
    "#EfficientNetV2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import EfficientNetV2L\n",
    "from tensorflow.keras.applications import EfficientNetV2L\n",
    "#import EfficientNetB7\n",
    "from tensorflow.keras.applications import EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetV2L(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6aae58",
   "metadata": {},
   "source": [
    "# consumer photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load consumer photos\n",
    "cp_photos = os.listdir('../../gen/output/consumer_photos_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show first pic\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open('../../gen/output/consumer_photos_category/' + cp_photos[0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351a4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show output image\n",
    "#save df as csv\n",
    "df.to_csv('cp_features.csv', index=False)\n",
    "plt.imshow(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e130a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def center_crop(image_d):\n",
    "    new_width =  min(image_d.size)\n",
    "    new_height =  min(image_d.size)\n",
    "    width, height = image_d.size\n",
    "    left = (width - new_width) / 2\n",
    "    top = (height - new_height) / 2\n",
    "    right = (width + new_width) / 2\n",
    "    bottom = (height + new_height) / 2\n",
    "    return image_d.crop((left, top, right, bottom))\n",
    "\n",
    "# Load image\n",
    "original_image = Image.open('../../gen/output/consumer_photos_category/' + cp_photos[2])\n",
    "\n",
    "# Perform center cropping\n",
    "cropped_image = center_crop(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1131f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show orginal\n",
    "plt.imshow(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show cropped\n",
    "plt.imshow(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec40bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model = EfficientNetV2L(weights='imagenet')\n",
    "#model = Model(inputs=model.input, outputs=model.get_layer('fc2').output)\n",
    "#make a dataframe with first column image name and second column image features\n",
    "df = pd.DataFrame(columns=['image', 'features_resized', 'features_cropped'])\n",
    "#extract features\n",
    "i = 0\n",
    "for img_d in cp_photos[0:5]:\n",
    "    #try:\n",
    "    input_image_path = '../../gen/output/consumer_photos_category/' + img_d\n",
    "    original_image = Image.open(input_image_path)\n",
    "\n",
    "    # Perform center cropping\n",
    "    cropped_image = center_crop(original_image)\n",
    "    cropped_image_resized = cropped_image.resize((460, 460))\n",
    "    img_data = image.img_to_array(cropped_image_resized)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    cp_feature_cropped = model.predict(img_data)\n",
    "\n",
    "    new_data = pd.DataFrame({'image': [img_d], 'features_cropped': [cp_feature_cropped]})\n",
    "    # Use pd.concat to append the new data\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "    if i % 100 == 0:\n",
    "        print(i, \" / \", len(cp_photos))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecff394",
   "metadata": {},
   "source": [
    "# Create blank image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32424dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model = EfficientNetV2L(weights='imagenet', include_top=True)\n",
    "#model = Model(inputs=model.input, outputs=model.get_layer('fc2').output)\n",
    "#make a dataframe with first column image name and second column image features\n",
    "df = pd.DataFrame(columns=['image', 'features_resized', 'features_cropped'])\n",
    "#extract features\n",
    "i = 0\n",
    "#try:\n",
    "#create a completely blank image\n",
    "original_image = Image.new('RGB', (460, 460), color = 'white')\n",
    "\n",
    "# Perform center cropping\n",
    "cropped_image = center_crop(original_image)\n",
    "cropped_image_resized = cropped_image.resize((460, 460))\n",
    "img_data = image.img_to_array(cropped_image_resized)\n",
    "img_data = np.expand_dims(img_data, axis=0)\n",
    "img_data = preprocess_input(img_data)\n",
    "cp_feature_cropped = model.predict(img_data)\n",
    "\n",
    "new_data = pd.DataFrame({'image': ['blank'], 'features_cropped': [cp_feature_cropped]})\n",
    "# Use pd.concat to append the new data\n",
    "df = pd.concat([df, new_data], ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
