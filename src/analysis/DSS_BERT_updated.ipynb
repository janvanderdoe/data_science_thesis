{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow_text (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow_text\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.read_csv('../../gen/output/amazon_search_hedonic_clean_merged.csv', sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select helpful and review\n",
    "df_m = df_m[['review', 'helpful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m['helpful'] = (df_m['helpful'] != 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataset\n",
    "df_m.to_csv('../../gen/output/review_helpful.csv', sep = \";\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This brand DVD player works great.  Will be bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This DVD player upscales all our DVD's.  Old D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 to 10 second delay in input from remote is a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Like I said a great picture, great value for t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This compact DVD player easily fit atop our co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121574</th>\n",
       "      <td>I went through 2 Samsung smart phones in the s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121575</th>\n",
       "      <td>I've only had it for a couple weeks, but it's ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121576</th>\n",
       "      <td>Don't buy this if you are trying to activate i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121577</th>\n",
       "      <td>Can't complain about speed, it performs fine.C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121578</th>\n",
       "      <td>Im the kind of user that jumps from iphone to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121579 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  helpful\n",
       "0       This brand DVD player works great.  Will be bu...        0\n",
       "1       This DVD player upscales all our DVD's.  Old D...        1\n",
       "2       5 to 10 second delay in input from remote is a...        0\n",
       "3       Like I said a great picture, great value for t...        0\n",
       "4       This compact DVD player easily fit atop our co...        0\n",
       "...                                                   ...      ...\n",
       "121574  I went through 2 Samsung smart phones in the s...        0\n",
       "121575  I've only had it for a couple weeks, but it's ...        0\n",
       "121576  Don't buy this if you are trying to activate i...        0\n",
       "121577  Can't complain about speed, it performs fine.C...        0\n",
       "121578  Im the kind of user that jumps from iphone to ...        1\n",
       "\n",
       "[121579 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m['review'] = df_m['review'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(data['review'])\n",
    "labels = list(data['helpful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_m.drop(columns=['helpful']), df_m['helpful'], test_size=0.6, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize texts and prepare for bert model\n",
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "def tokenize_sentences(sentences, tokenizer, max_seq_len = 128):\n",
    "    tokenized_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokenized_sentence = tokenizer.encode(sentence, add_special_tokens = True, max_length = max_seq_len, truncation = True)\n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "\n",
    "    return tokenized_sentences\n",
    "\n",
    "def create_attention_masks(tokenized_and_padded_sentences):\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in tokenized_and_padded_sentences:\n",
    "        att_mask = [int(token_id > 0) for token_id in sentence]\n",
    "        attention_masks.append(att_mask)\n",
    "\n",
    "    return np.array(attention_masks)\n",
    "\n",
    "def create_model_inputs(df, tokenizer, max_seq_len):\n",
    "    tokenized_sentences = tokenize_sentences(df['review'], tokenizer, max_seq_len)\n",
    "    padded_sentences = pad_sequences(tokenized_sentences, maxlen=max_seq_len, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "    attention_masks = create_attention_masks(padded_sentences)\n",
    "\n",
    "    return padded_sentences, attention_masks\n",
    "\n",
    "max_seq_len = 128\n",
    "\n",
    "X_train_input = create_model_inputs(X_train, tokenizer, max_seq_len)\n",
    "X_val_input = create_model_inputs(X_val, tokenizer, max_seq_len)\n",
    "X_test_input = create_model_inputs(X_test, tokenizer, max_seq_len)\n",
    "\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "def create_model():\n",
    "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 2)\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train_input, y_train, epochs = 1, batch_size = 32, validation_data = (X_val_input, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install tensorflow_text\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make text_dataset from X_train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train['review'].values, y_train.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create  tf.data.Datasets\n",
    "import tensorflow as tf\n",
    "#import tensorflow_text as text\n",
    "\n",
    "X_train = tf.data.Dataset.from_tensor_slices((X_train['review'].values, y_train.values))\n",
    "X_val = tf.data.Dataset.from_tensor_slices((X_val['review'].values, y_val.values))\n",
    "X_test = tf.data.Dataset.from_tensor_slices((X_test['review'].values, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'never purchases dvd plyer', shape=(), dtype=string)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(b\"I'm so glad I invested the inexpensive amount of money for this wonderful, and so easy to install, multi-format player!! It has opened an entire new world of blu-ray and DVDs from other Regions of the world that are actually in English,  copied in other region playing formats. There are some great classics in blu-ray like Long Hot Summer and Love With the Proper Stranger for Paul Newman and Steve McQueen fans, and many more newer films. Some people are purists, like myself, and want Blu-rays. Some are fine with DVDs and that's okay too. For the money and the opportunity to view films I wouldn't be able to otherwise, it's worth every penny!\", shape=(), dtype=string)\n",
      "tf.Tensor(6.0, shape=(), dtype=float64)\n",
      "tf.Tensor(b\"Just got this off the porch where it was delivered. Opened the box, put it together quickly and easily. My mother's downstairs apartment was covered in dog hair from her shedding black lab on white carpet. ABSOLUTELY FABULOUS suction. Got the nooks and corners, got under tables and the swivel head makes it so much easier. Suction on 3 sides helps a lot too. No need for the attachments along walls, just picks it all right up without a fuss. It has a suction indicator so you know when the canister is full. One touch easy peasy empty. Could not be happier. It is a heavy vacuum though. I do not think I would try to carry it up and down the stairs. But it has attachments and a very long cord and pretty good reach on the hose. So not much need to carry it anyway. Cord retracts with the touch of a button. Love it. I almost wanna go brush the lab so I can use it again... almost. Lol\", shape=(), dtype=string)\n",
      "tf.Tensor(61.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#show text and labels\n",
    "for text, label in X_train.take(3):\n",
    "    print(text)\n",
    "    print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
